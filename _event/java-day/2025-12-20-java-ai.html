---
title:  "Java and AI Mini Conference"
date:   2025-12-20 09:00:00
start: "9:00"
end: "15:00"
location: "Netaville"
agenda:
 - from: "9:00"
   to: "10:00"
   talk: "Registration and coffee"
   speakers: []
 - from: "10:00"
   to: "10:40"
   talk: "Unified In-Context Learning: Integrating Raw Telemetry and Natural Language Directives for Zero-Shot Forecasting"
   description: Traditional time series forecasting requires complex statistical pipelines, specialized coding, and isolated data environments. This presentation details the initial findings of an exploratory research effort into Instructionable Time Series Analysis, a novel approach leveraging the in-context learning capabilities of Large Language Models (LLMs). We present early evidence demonstrating how raw temporal data and natural language directives can be unified within a single interpretation. This initial success suggests a strong potential for allowing non-experts to execute sophisticated tasks, such as data imputation and multi-step forecasting through conversational directives, which could significantly reduce the time-to-insight in data analysis workflows.
   speakers: [0, 1]
   index: 0  
 - from: "10:40"
   to: "11:00"
   talk: "Break"
   speakers: []
 - from: "11:00"
   to: "11:40"
   talk: "AI-driven reverse engineering"
   description: In this session we will reveal how can AI help us analyse better code repositories allowing us to speed up the process of reverse engineering an unknown codebase.
   speakers: [2]
   index: 3
 - from: "11:40"
   to: "12:00"
   talk: "Break"
   speakers: []
 - from: "12:00"
   to: "12:20"
   talk: "Gen AI with local models and LangChain4j on 2 x NVIDIA Sparks"
   description: This talk demonstrates a fully local GenAI development setup, presented live on two physical NVIDIA Spark machines, running offline LLMs such as GPT-OSS and Qwen models. We show how the two Spark PCs are networked on-site to form a small local inference environment, covering practical configuration choices, hardware constraints, and common pitfalls of GPU-based local development. In the second part, we showcase how LangChain4j can be used with local models to implement prompting, Retrieval-Augmented Generation (RAG), and simple agent-style workflows. All demos are executed live on the two NVIDIA Spark machines, giving the audience a concrete, hands-on view of what local GenAI development looks like in practice.
   speakers: [3, 1]
   index: 4
 - from: "12:20"
   to: "12:30"
   talk: "Short break"
   speakers: []
 - from: "12:30"
   to: "12:50"
   talk: "Implementing Human-In-The-Loop with LangGraph4j"
   description: Inspired by Python’s library LangGraph, the Java library LangGraph4j offers the opportunity to build stateful, multi-agent applications with Large Language Models (LLMs). This talk will highlight how LangGraph4j’s graph-based workflow engine makes it possible to combine LLM steps with human review.
   speakers: [4]
   index: 5
 - from: "12:50"
   to: "13:00"
   talk: Short break
   speakers: []
 - from: "13:00"
   to: "13:40"
   talk: "Java and GenAI: from basics to enterprise"
   description: Java GenAI libraries are getting more mature as every day passes by. A lot of examples and documentation are available, but the business needs are on a different level. This talk will show the path from starting integration towards enterprise ready implementations. 
   speakers: [5]
   index: 6
 - from: "13:40"
   to: "15:00"
   talk: Beer and networking
   speakers: []
---
<div style="text-align: center; "><img src="/images/jugmkai.png" style="width: 100%;" /><br/></div>
{% include date_location_time.html %}

{% assign speakers = site.data.speakers-2025 %}

{% include agenda.html %}

{% include speaker_abstract.html %}
